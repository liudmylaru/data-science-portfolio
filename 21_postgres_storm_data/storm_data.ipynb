{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Storm Data\n",
    "\n",
    "The International Hurricane Watchgroup (IHW) has been asked to update their analysis tools. Because of the increase in public awareness of hurricanes, they are required to be more diligient with the analysis of historical hurricane data they share across the organization. \n",
    "\n",
    "The team of IHW have been having trouble sharing data across the teams and keeping it consistent. It seems that their method of sharing the data with their data anaylsts has been to save a CSV file on their local servers and have every data analyst pull the data down. Then, each analyst uses a local SQLite engine to store the CSV, run their queries, and send their results around.\n",
    "\n",
    "Their CSV file contains the following fields:\n",
    "\n",
    "* **fid** - ID for the row\n",
    "* **year** - Recorded year\n",
    "* **month** - Recorded month\n",
    "* **day** - Recorded date\n",
    "* **ad_time** - Recorded time in UTC\n",
    "* **btid** - Hurricane ID\n",
    "* **name** - Name of the hurricane\n",
    "* **lat** - Latitude of the recorded location\n",
    "* **long** - Longitude of the recorded location\n",
    "* **wind_kts** - Wind speed in knots per second\n",
    "* **pressure** - Atmospheric pressure of the hurricane\n",
    "* **cat** - Hurricane category\n",
    "* **basin** - The basin the hurricane is located\n",
    "* **shape_leng** - Hurricane shape length\n",
    "\n",
    "The goal is to create a database that will accomplish the following requirements:\n",
    "\n",
    "* Database for the IHW to store their tables.\n",
    "* Table that contains the fields detailed in the CSV file\n",
    "* User that can update, read, and insert into a table of the data.\n",
    "* Insert the data into the table.\n",
    "\n",
    "## Download the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffFID', 'YEAR', 'MONTH', 'DAY', 'AD_TIME', 'BTID', 'NAME', 'LAT', 'LONG', 'WIND_KTS', 'PRESSURE', 'CAT', 'BASIN', 'Shape_Leng']\n",
      "['2001', '1957', '8', '8', '1800Z', '63', 'NOTNAMED', '22.5', '-140', '50', '0', 'TS', 'Eastern Pacific', '1.140175']\n",
      "['2002', '1961', '10', '3', '1200Z', '116', 'PAULINE', '22.1', '-140.2', '45', '0', 'TS', 'Eastern Pacific', '1.16619']\n",
      "['2003', '1962', '8', '29', '0600Z', '124', 'C', '18', '-140', '45', '0', 'TS', 'Eastern Pacific', '2.10238']\n",
      "['2004', '1967', '7', '14', '0600Z', '168', 'DENISE', '16.6', '-139.5', '45', '0', 'TS', 'Eastern Pacific', '2.12132']\n",
      "['2005', '1972', '8', '16', '1200Z', '251', 'DIANA', '18.5', '-139.8', '70', '0', 'H1', 'Eastern Pacific', '1.702939']\n",
      "['2006', '1976', '7', '22', '0000Z', '312', 'DIANA', '18.6', '-139.8', '30', '0', 'TD', 'Eastern Pacific', '1.6']\n",
      "['2007', '1978', '8', '26', '1200Z', '342', 'KRISTY', '21.4', '-140.2', '45', '0', 'TS', 'Eastern Pacific', '1.30384']\n",
      "['2008', '1980', '9', '24', '1800Z', '371', 'KAY', '20.5', '-140.2', '75', '0', 'H1', 'Eastern Pacific', '1.220656']\n",
      "['2009', '1970', '8', '23', '0000Z', '223', 'MAGGIE', '14.9', '-139.4', '45', '0', 'TS', 'Eastern Pacific', '0.921954']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "from urllib import request\n",
    "import pandas as pd\n",
    "\n",
    "response = request.urlopen('https://dq-content.s3.amazonaws.com/251/storm_data.csv')\n",
    "reader = csv.reader(io.TextIOWrapper(response))\n",
    "\n",
    "count = 10\n",
    "for line in reader:\n",
    "    if count == 0:\n",
    "        break\n",
    "    else:\n",
    "        print(line)\n",
    "        count -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "\n",
    "In the `FID` column numbers vary between 2001 and on. From first observation, it already exceeds the small integer type. This column fits within the INTEGER size.\n",
    "\n",
    "The last column, shape length, seems to keep the same precision of 1 digit before the decimal and 6 digits after.  Using DECIMAL can specify a max scale and precision that will ensure the data stays within the ranges.\n",
    "\n",
    "## Create the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            (fid, 23, None, 4, None, None, None)\n",
      "1     (datetime, 1184, None, 8, None, None, None)\n",
      "2           (btid, 23, None, 4, None, None, None)\n",
      "3          (name, 25, None, -1, None, None, None)\n",
      "4                (lat, 1700, None, 4, 4, 1, None)\n",
      "5               (long, 1700, None, 4, 4, 1, None)\n",
      "6       (wind_kts, 21, None, 2, None, None, None)\n",
      "7       (pressure, 21, None, 2, None, None, None)\n",
      "8          (cat, 1043, None, 2, None, None, None)\n",
      "9         (basin, 25, None, -1, None, None, None)\n",
      "10        (shape_leng, 1700, None, 8, 8, 6, None)\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname='lucy', user='lucy')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "   DROP TABLE IF EXISTS storm_data\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "   CREATE TABLE storm_data (\n",
    "       fid INTEGER PRIMARY KEY,\n",
    "       datetime TIMESTAMP with time zone,\n",
    "       btid INTEGER,\n",
    "       name TEXT,\n",
    "       lat DECIMAL(4,1), \n",
    "       long DECIMAL(4,1),\n",
    "       wind_kts SMALLINT,\n",
    "       pressure SMALLINT,\n",
    "       cat VARCHAR(2),\n",
    "       basin TEXT,\n",
    "       shape_leng DECIMAL(8,6)\n",
    "   )\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "cur.execute('SELECT * FROM storm_data LIMIT 0')\n",
    "print(pd.Series(cur.description))\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create the Users\n",
    "\n",
    "With a table set up, it's now time to create a user on the Postgres database that can insert, update, and read the data but not delete. This is to make sure that someone who might get a hold of this user does not issue a destructive command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='lucy', user='lucy')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    DROP GROUP IF EXISTS analyst;\n",
    "    CREATE GROUP analyst NOLOGIN;\n",
    "    REVOKE ALL ON storm_data FROM analyst;\n",
    "    GRANT SELECT, INSERT, UPDATE ON storm_data TO analyst;\n",
    "    DROP USER IF EXISTS john;\n",
    "    CREATE USER john WITH CREATEDB PASSWORD 'watson' IN GROUP analyst;\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('public.storm_data',)]\n"
     ]
    }
   ],
   "source": [
    "conn_john = psycopg2.connect(dbname='lucy', user='john', password='watson')\n",
    "cur_john = conn_john.cursor()\n",
    "cur_john.execute(\"\"\"\n",
    "    SELECT\n",
    "     table_schema || '.' || table_name\n",
    " FROM\n",
    "     information_schema.tables\n",
    " WHERE\n",
    "     table_type = 'BASE TABLE'\n",
    " AND\n",
    "     table_schema NOT IN ('pg_catalog', 'information_schema');\n",
    "\"\"\")\n",
    "print(cur_john.fetchall())\n",
    "conn_john.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "conn = psycopg2.connect(dbname='lucy', user='lucy')\n",
    "cur = conn.cursor()\n",
    "\n",
    "## take data from file with columns:\n",
    "## FID', 'YEAR', 'MONTH', 'DAY', 'AD_TIME', 'BTID', 'NAME', 'LAT', \n",
    "##'LONG', 'WIND_KTS', 'PRESSURE', 'CAT', 'BASIN', 'Shape_Leng'\n",
    "## insert into table with columns:\n",
    "## fid, datetime, btid, name, lat, long, wind_kts, pressure, cat, basin, shape_leng\n",
    "response = request.urlopen('https://dq-content.s3.amazonaws.com/251/storm_data.csv')\n",
    "reader = csv.reader(io.TextIOWrapper(response))\n",
    "next(reader)\n",
    "\n",
    "for line in reader:\n",
    "    datetime_data = datetime(int(line[1]), int(line[2]), int(line[3]), int(line[4][:2]), int(line[4][2:4]))\n",
    "    row = line[5:]\n",
    "    row.insert(0, line[0])\n",
    "    row.insert(1, datetime_data)    \n",
    "    cur.execute(\"INSERT INTO storm_data VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\", row)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0                          1    2         3     4       5   6   7   8   \\\n",
      "0  2001  1957-08-08 18:00:00-07:00   63  NOTNAMED  22.5  -140.0  50   0  TS   \n",
      "1  2002  1961-10-03 12:00:00-08:00  116   PAULINE  22.1  -140.2  45   0  TS   \n",
      "2  2003  1962-08-29 06:00:00-07:00  124         C  18.0  -140.0  45   0  TS   \n",
      "3  2004  1967-07-14 06:00:00-07:00  168    DENISE  16.6  -139.5  45   0  TS   \n",
      "4  2005  1972-08-16 12:00:00-07:00  251     DIANA  18.5  -139.8  70   0  H1   \n",
      "\n",
      "                9         10  \n",
      "0  Eastern Pacific  1.140175  \n",
      "1  Eastern Pacific  1.166190  \n",
      "2  Eastern Pacific  2.102380  \n",
      "3  Eastern Pacific  2.121320  \n",
      "4  Eastern Pacific  1.702939  \n"
     ]
    }
   ],
   "source": [
    "conn_john = psycopg2.connect(dbname='lucy', user='john', password='watson')\n",
    "cur_john = conn_john.cursor()\n",
    "cur_john.execute(\"\"\"\n",
    "    SELECT * FROM storm_data LIMIT 5\n",
    "\"\"\")\n",
    "print(pd.DataFrame(cur_john.fetchall()))\n",
    "conn_john.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
